# -*- coding: utf-8 -*-
"""ncaa_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YTpQfzX539ltDXDxGcA1BYh0fTRuHaq2
"""

# Commented out IPython magic to ensure Python compatibility.
# Allows multiple outputs from a single cell:
from IPython.core.interactiveshell import InteractiveShell as IS; IS.ast_node_interactivity = "all"
!pip -q install -U statsmodels > log.txt   # ensures no FutureWarnings from statsmodels

import pandas as pd, numpy as np, statsmodels.api as sm, pprint, math, seaborn as sns, matplotlib.pyplot as plt, sklearn as sk
from scipy import stats as stat

from math import floor
from termcolor import colored

from sklearn.datasets import make_classification
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split as tts
from sklearn.metrics import r2_score, roc_auc_score, roc_curve, auc, confusion_matrix
from datetime import datetime as dt

# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/Data/ncaa_model.csv')

df

plt.rcParams['figure.figsize'] = [20, 10]
ax = sns.heatmap(df.isnull().T, cmap = "BuPu", cbar=False);
ax.set_title('Missing values (in dark)');

plt.style.use('fivethirtyeight')
fig, ax = plt.subplots(figsize=(25,10))
sns.heatmap(df.corr().round(2), annot=True, cmap='Spectral_r', ax=ax, linecolor= 'black', linewidth = 1.0)
ax.set_title(f'Correlation Heatmap for NCAA Model', color = 'black', fontsize= 14)
plt.tight_layout();

# Loading the data for the 2023 NCAA teams

df_new = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/Data/ncaa_2023.csv')
df_new_team = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/Data/ncaa_2023.csv')
df_new.drop(columns = ['year','team', 'region','ap_pre','ap_high','ap_final'], inplace=True)
df_new['const'] = 1

# Creating a new dataframe before calculating the second round teams
df_32 = df.copy()

# Dropping Columns that won't be used in the modeling

df_32.drop(columns = ['team','region','conf','year','sixteen','eight','four','championship','nat_champ','ap_pre','ap_high','ap_final'], inplace=True)

# Adding a constant to the model

df_32['const'] = 1

# Creating model

tX0, vX0, tY0, vY0 = tts(df_32.drop(['thirtytwo'], axis=1), df_32['thirtytwo'], test_size = 0.2, random_state=123)

# Logistic regression model summary

md0 = sm.Logit(tY0, tX0).fit()
print(md0.summary(title='NCAA Model - Second Round', alpha=.05))

# Creating prediction probabilities and labels

pY_prob0 = md0.predict(vX0)
pY_prob0 = pY_prob0
pY0 = (pY_prob0 > 0.9) * 1
AUC = roc_auc_score(vY0, pY_prob0)

# Creating confusion matrix

dfCM = pd.DataFrame(confusion_matrix(vY0, pY0), index=['True-','True+'], columns=['Pred-','Pred+'])
print(f'Confusion matrix:\n{dfCM}')
print(f'Out of sample accuracy: {np.mean(pY0 == vY0):.2f} and AUC:{AUC:.2f}')

# Creating ROC & AUC plot

fpr, tpr, thresholds = roc_curve(vY0, pY_prob0)

plt.rcParams['figure.figsize'] = [5, 5]
ax = pd.DataFrame([fpr, tpr], index=['fpr','tpr']).T.plot(
    'fpr','tpr', kind='line', grid=True, title='Receiver Operating Characteristic', label=f'ROC curve. AUC = {AUC:.2f}');

ax.plot([0, 1], [0, 1], 'r--');  # random predictions curve
ax.set_ylabel('True Positive Rate or (Sensitivity)');
ax.set_xlabel('False Positive Rate or (1 - Specifity)');

# Fitting the model to the 2023 NCAA Teams

pY_prob0 = md0.predict(df_new)
pY_prob0 = pY_prob0
pY0 = (pY_prob0 > 0.9) * 1

# Printing 2023 NCAA teams prediction probabilites and prediction labels for the second round

df_prob = pd.Series(pY_prob0)
df_prob = pd.DataFrame(df_prob, columns=['prob'])
df_pred = pd.DataFrame(pY0, columns=['thirtytwo'])
prediction_results =df_prob.merge(df_pred['thirtytwo'], left_index=True, right_index=True)
prediction_results = prediction_results.merge(df_new_team['team'], left_index=True, right_index=True).merge(df_new_team['seed'], left_index=True, right_index=True).merge(df_new_team['region'], left_index=True, right_index=True)\
.merge(df_new_team['conf_champ'], left_index=True, right_index=True).merge(df_new_team['tourn_champ'], left_index=True, right_index=True).merge(df_new_team['sag_rate'], left_index=True, right_index=True).merge(df_new_team['kp_em_rnk'], left_index=True, right_index=True)\
.merge(df_new_team['kp_ornk'], left_index=True, right_index=True).merge(df_new_team['kp_drnk'], left_index=True, right_index=True).merge(df_new_team['kp_lucrnk'], left_index=True, right_index=True).merge(df_new_team['kp_sosrnk'], left_index=True, right_index=True)\
.merge(df_new_team['ap_final'], left_index=True, right_index=True).merge(df_new_team['new_coach'], left_index=True, right_index=True)
prediction_results.sort_values(['prob'], ascending=False)

# Creating a new dataframe before calculating the sweet sixteen teams

df_16 = df.copy()

# Dropping columns that won't be used in the modeling

df_16.drop(columns = ['team','region','conf','year','thirtytwo','eight','four','championship','nat_champ','ap_pre','ap_high','ap_final'], inplace=True)

# Adding a constant to the model

df_16['const'] = 1

# Creating model

tX1, vX1, tY1, vY1 = tts(df_16.drop(['sixteen'], axis=1), df_16['sixteen'], test_size = 0.2, random_state=123)

md1 = sm.Logit(tY1, tX1).fit(method = 'powell')
print(md1.summary(title='NCAA Model - Sweet Sixteen ', alpha=.05))

# Creating prediction probabilities and labels

pY_prob1 = md1.predict(vX1)
pY_prob1 = pY_prob1
pY1 = (pY_prob1 > 0.85) * 1
AUC = roc_auc_score(vY1, pY_prob1)

# Creating confusion matrix

dfCM = pd.DataFrame(confusion_matrix(vY1, pY1), index=['True-','True+'], columns=['Pred-','Pred+'])
print(f'Confusion matrix:\n{dfCM}')
print(f'Out of sample accuracy: {np.mean(pY1 == vY1):.2f} and AUC:{AUC:.2f}')

# Creating ROC and AUC plot

fpr, tpr, thresholds = roc_curve(vY1, pY_prob1)

plt.rcParams['figure.figsize'] = [5, 5]
ax = pd.DataFrame([fpr, tpr], index=['fpr','tpr']).T.plot(
    'fpr','tpr', kind='line', grid=True, title='Receiver Operating Characteristic', label=f'ROC curve. AUC = {AUC:.2f}');

ax.plot([0, 1], [0, 1], 'r--');  # random predictions curve
ax.set_ylabel('True Positive Rate or (Sensitivity)');
ax.set_xlabel('False Positive Rate or (1 - Specifity)');

# Fitting the model to the 2023 NCAA Teams

pY_prob1 = md1.predict(df_new)
pY_prob1 = pY_prob1
pY1 = (pY_prob1 > 0.85) * 1

# Printing 2023 NCAA teams prediction probabilites and prediction labels for the sweet sixteen

df_prob = pd.Series(pY_prob1)
df_prob = pd.DataFrame(df_prob, columns=['prob'])
df_pred = pd.DataFrame(pY1, columns=['sixteen'])
prediction_results =df_prob.merge(df_pred['sixteen'], left_index=True, right_index=True)
prediction_results = prediction_results.merge(df_new_team['team'], left_index=True, right_index=True).merge(df_new_team['seed'], left_index=True, right_index=True).merge(df_new_team['region'], left_index=True, right_index=True)\
.merge(df_new_team['conf_champ'], left_index=True, right_index=True).merge(df_new_team['tourn_champ'], left_index=True, right_index=True).merge(df_new_team['sag_rate'], left_index=True, right_index=True).merge(df_new_team['kp_em_rnk'], left_index=True, right_index=True)\
.merge(df_new_team['kp_ornk'], left_index=True, right_index=True).merge(df_new_team['kp_drnk'], left_index=True, right_index=True)\
.merge(df_new_team['kp_lucrnk'], left_index=True, right_index=True).merge(df_new_team['ap_final_rnk'], left_index=True, right_index=True).merge(df_new_team['ap_final'], left_index=True, right_index=True)
prediction_results.sort_values(['prob'], ascending=False)

# Creating a new dataframe before calculating the elite eight teams

df_8 = df.copy()

# Dropping columns that won't be used in the modeling

df_8.drop(columns = ['team','region','conf','year','thirtytwo','sixteen','four','championship','nat_champ','ap_pre','ap_high','ap_final'], inplace=True)

# Adding a constant to the model

df_8['const'] = 1

tX2, vX2, tY2, vY2 = tts(df_8.drop(['eight'], axis=1), df_8['eight'], test_size = 0.2, random_state=123)

md2 = sm.Logit(tY2, tX2).fit(method = 'ncg')
print(md2.summary(title='NCAA Model - Elite Eight', alpha=.05))

pY_prob2 = md2.predict(vX2)
pY_prob2 = pY_prob2
pY2 = (pY_prob2 > 0.50) * 1
AUC = roc_auc_score(vY2, pY_prob2)

dfCM = pd.DataFrame(confusion_matrix(vY2, pY2), index=['True-','True+'], columns=['Pred-','Pred+'])
print(f'Confusion matrix:\n{dfCM}')
print(f'Out of sample accuracy: {np.mean(pY2 == vY2):.2f} and AUC:{AUC:.2f}')

fpr, tpr, thresholds = roc_curve(vY2, pY_prob2)

plt.rcParams['figure.figsize'] = [5, 5]
ax = pd.DataFrame([fpr, tpr], index=['fpr','tpr']).T.plot(
    'fpr','tpr', kind='line', grid=True, title='Receiver Operating Characteristic', label=f'ROC curve. AUC = {AUC:.2f}');

ax.plot([0, 1], [0, 1], 'r--');  # random predictions curve
ax.set_ylabel('True Positive Rate or (Sensitivity)');
ax.set_xlabel('False Positive Rate or (1 - Specifity)');

# Fitting the model to the 2023 NCAA Teams
pY_prob2 = md2.predict(df_new)
pY_prob2 = pY_prob2
pY2 = (pY_prob2 > 0.5) * 1

df_prob = pd.Series(round(pY_prob2,2))
df_prob = pd.DataFrame(df_prob, columns=['prob'])
df_pred = pd.DataFrame(pY2, columns=['eight'])
prediction_results =df_prob.merge(df_pred['eight'], left_index=True, right_index=True)
prediction_results = prediction_results.merge(df_new_team['team'], left_index=True, right_index=True).merge(df_new_team['seed'], left_index=True, right_index=True).merge(df_new_team['region'], left_index=True, right_index=True)\
.merge(df_new_team['conf_champ'], left_index=True, right_index=True).merge(df_new_team['tourn_champ'], left_index=True, right_index=True).merge(df_new_team['sag_sche'], left_index=True, right_index=True)\
.merge(df_new_team['sag_rate'], left_index=True, right_index=True).merge(df_new_team['kp_em_rnk'], left_index=True, right_index=True).merge(df_new_team['kp_ornk'], left_index=True, right_index=True)\
.merge(df_new_team['kp_drnk'], left_index=True, right_index=True).merge(df_new_team['kp_lucrnk'], left_index=True, right_index=True).merge(df_new_team['ap_pre'], left_index=True, right_index=True).merge(df_new_team['ap_final'], left_index=True, right_index=True)
prediction_results.sort_values(['prob'], ascending=False)

# Creating a new dataframe before calculating the final four teams

df_4 = df.copy()

# Dropping columns that won't be used in the modeling

df_4.drop(columns = ['team','region','conf','year','thirtytwo','sixteen','eight','championship','nat_champ','ap_pre','ap_high','ap_final'], inplace=True)

# Adding a constant to the model

df_4['const'] = 1

tX3, vX3, tY3, vY3 = tts(df_4.drop(['four'], axis=1), df_4['four'], test_size = 0.2, random_state=123)

# Logistic regression model summary

md3 = sm.Logit(tY3, tX3).fit(method = 'ncg')
print(md3.summary(title='NCAA Model - Final Four', alpha=.05))

pY_prob3 = md3.predict(vX3)
pY_prob3 = pY_prob3
pY3 = (pY_prob3 > 0.72) * 1
#AUC = roc_auc_score(vY3, pY_prob3)

dfCM = pd.DataFrame(confusion_matrix(vY3, pY3), index=['True-','True+'], columns=['Pred-','Pred+'])
print(f'Confusion matrix:\n{dfCM}')
print(f'Out of sample accuracy: {np.mean(pY3 == vY3):.2f} and AUC:{AUC:.2f}')

fpr, tpr, thresholds = roc_curve(vY3, pY_prob3)

plt.rcParams['figure.figsize'] = [5, 5]
ax = pd.DataFrame([fpr, tpr], index=['fpr','tpr']).T.plot(
    'fpr','tpr', kind='line', grid=True, title='Receiver Operating Characteristic', label=f'ROC curve. AUC = {AUC:.2f}');

ax.plot([0, 1], [0, 1], 'r--');  # random predictions curve
ax.set_ylabel('True Positive Rate or (Sensitivity)');
ax.set_xlabel('False Positive Rate or (1 - Specifity)');

# Fitting the model to the 2023 NCAA Teams
pY_prob3 = md3.predict(df_new)
pY_prob3 = pY_prob3
pY3 = (pY_prob3 > 0.72) * 1

df_prob = pd.Series(round(pY_prob3,2))
df_prob = pd.DataFrame(df_prob, columns=['prob'])
df_pred = pd.DataFrame(pY3, columns=['four'])
prediction_results =df_prob.merge(df_pred['four'], left_index=True, right_index=True)
prediction_results = prediction_results.merge(df_new_team['team'], left_index=True, right_index=True).merge(df_new_team['seed'], left_index=True, right_index=True).merge(df_new_team['region'], left_index=True, right_index=True)\
.merge(df_new_team['conf_champ'], left_index=True, right_index=True).merge(df_new_team['tourn_champ'], left_index=True, right_index=True).merge(df_new_team['sag_rate'], left_index=True, right_index=True)\
.merge(df_new_team['kp_em_rnk'], left_index=True, right_index=True).merge(df_new_team['kp_ornk'], left_index=True, right_index=True).merge(df_new_team['kp_drnk'], left_index=True, right_index=True)\
.merge(df_new_team['kp_lucrnk'], left_index=True, right_index=True).merge(df_new_team['ap_pre'], left_index=True, right_index=True).merge(df_new_team['ap_final'], left_index=True, right_index=True)
prediction_results.sort_values(['prob'], ascending=False)

# Creating a new dataframe before calculating the championship teams

df_2 = df.copy()

# Dropping columns that won't be used in the modeling

df_2.drop(columns = ['team','region','conf','year','thirtytwo','sixteen','eight','four','nat_champ','ap_pre','ap_high','ap_final'], inplace=True)

# Adding a constant to the model

df_2['const'] = 1

tX4, vX4, tY4, vY4 = tts(df_2.drop(['championship'], axis=1), df_2['championship'], test_size = 0.2, random_state=123)

# Logistic regression model summary

md4 = sm.Logit(tY4, tX4).fit(method='ncg')
print(md4.summary(title='NCAA Model - Championship Game', alpha=.05))

pY_prob4 = md4.predict(vX4)
pY_prob4 = pY_prob4
pY4 = (pY_prob4 > 0.25) * 1
#AUC = roc_auc_score(vY4, pY_prob4)

#dfCM = pd.DataFrame(confusion_matrix(vY4, pY4), index=['True-','True+'], columns=['Pred-','Pred+'])
#print(f'Confusion matrix:\n{dfCM}')
print(f'Out of sample accuracy: {np.mean(pY4 == vY4):.2f} and AUC:{AUC:.2f}')

fpr, tpr, thresholds = roc_curve(vY4, pY_prob4)

plt.rcParams['figure.figsize'] = [5, 5]
ax = pd.DataFrame([fpr, tpr], index=['fpr','tpr']).T.plot(
    'fpr','tpr', kind='line', grid=True, title='Receiver Operating Characteristic', label=f'ROC curve. AUC = {AUC:.2f}');

ax.plot([0, 1], [0, 1], 'r--');  # random predictions curve
ax.set_ylabel('True Positive Rate or (Sensitivity)');
ax.set_xlabel('False Positive Rate or (1 - Specifity)');

# Fitting the model to the 2023 NCAA Teams
pY_prob4 = md4.predict(df_new)
pY_prob4 = pY_prob4
pY4 = (pY_prob4 > 0.25) * 1

df_prob = pd.Series(round(pY_prob4,3))
df_prob = pd.DataFrame(df_prob, columns=['prob'])
df_pred = pd.DataFrame(pY4, columns=['champgame'])
prediction_results =df_prob.merge(df_pred['champgame'], left_index=True, right_index=True)
prediction_results = prediction_results.merge(df_new_team['team'], left_index=True, right_index=True).merge(df_new_team['seed'], left_index=True, right_index=True).merge(df_new_team['region'], left_index=True, right_index=True)\
.merge(df_new_team['conf_champ'], left_index=True, right_index=True).merge(df_new_team['tourn_champ'], left_index=True, right_index=True).merge(df_new_team['sag_rate'], left_index=True, right_index=True).merge(df_new_team['kp_ornk'], left_index=True, right_index=True)\
.merge(df_new_team['kp_lucrnk'], left_index=True, right_index=True).merge(df_new_team['ap_final'], left_index=True, right_index=True)
prediction_results.sort_values(['prob'], ascending=False)

# Creating a new dataframe before calculating the championship teams

df_1 = df.copy()

# Dropping columns that won't be used in the modeling

df_1.drop(columns = ['team','region','conf','year','thirtytwo','sixteen','eight','four','championship','ap_pre','ap_high','ap_final'], inplace=True)

# Adding a constant to the model

df_1['const'] = 1

tX5, vX5, tY5, vY5 = tts(df_1.drop(['nat_champ'], axis=1), df_1['nat_champ'], test_size = 0.2, random_state=123)

# Logistic regression model summary

md5 = sm.Logit(tY5, tX5).fit(method='minimize') #method='ncg'
print(md5.summary(title='NCAA Model - Championship Game', alpha=.05))

pY_prob5 = md5.predict(vX5)
pY_prob5 = pY_prob5
pY5 = (pY_prob5 > 0.25) * 1
#AUC = roc_auc_score(vY5, pY_prob5)

#dfCM = pd.DataFrame(confusion_matrix(vY4, pY4), index=['True-','True+'], columns=['Pred-','Pred+'])
#print(f'Confusion matrix:\n{dfCM}')
print(f'Out of sample accuracy: {np.mean(pY5 == vY5):.2f}') 
# and AUC:{AUC:.2f}')

fpr, tpr, thresholds = roc_curve(vY5, pY_prob5)

plt.rcParams['figure.figsize'] = [5, 5]
#ax = pd.DataFrame([fpr, tpr], index=['fpr','tpr']).T.plot(
#    'fpr','tpr', kind='line', grid=True, title='Receiver Operating Characteristic', label=f'ROC curve. AUC = {AUC:.2f}');

ax.plot([0, 1], [0, 1], 'r--');  # random predictions curve
ax.set_ylabel('True Positive Rate or (Sensitivity)');
ax.set_xlabel('False Positive Rate or (1 - Specifity)');

# Fitting the model to the 2023 NCAA Teams
pY_prob5 = md5.predict(df_new)
pY_prob5 = pY_prob5
pY5 = (pY_prob5 > 0.25) * 1

df_prob = pd.Series(round(pY_prob5,3))
df_prob = pd.DataFrame(df_prob, columns=['prob'])
df_pred = pd.DataFrame(pY5, columns=['champion'])
prediction_results =df_prob.merge(df_pred['champion'], left_index=True, right_index=True)
prediction_results = prediction_results.merge(df_new_team['team'], left_index=True, right_index=True).merge(df_new_team['seed'], left_index=True, right_index=True).merge(df_new_team['region'], left_index=True, right_index=True)\
.merge(df_new_team['conf_champ'], left_index=True, right_index=True).merge(df_new_team['tourn_champ'], left_index=True, right_index=True).merge(df_new_team['sag_rate'], left_index=True, right_index=True).merge(df_new_team['kp_ornk'], left_index=True, right_index=True)\
.merge(df_new_team['kp_lucrnk'], left_index=True, right_index=True).merge(df_new_team['ap_final'], left_index=True, right_index=True)
prediction_results.sort_values(['prob'], ascending=False)